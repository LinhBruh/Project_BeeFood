version: '3.8'

services:
  mongo:
    image: mongo:latest
    container_name: mongo
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  mongo-express:
    image: mongo-express:latest
    container_name: mongo-express
    ports:
      - "8085:8085"
    environment:
      ME_CONFIG_MONGODB_SERVER: mongo
      ME_CONFIG_MONGODB_PORT: 27017
      ME_CONFIG_BASICAUTH_USERNAME: admin
      ME_CONFIG_BASICAUTH_PASSWORD: admin123

  postgres:
    image: postgres:13
    container_name: postgres
    environment:
      POSTGRES_USER: befood
      POSTGRES_PASSWORD: befood123
      POSTGRES_DB: befood_db
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  pgadmin:
    image: dpage/pgadmin4
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@befood.com
      PGADMIN_DEFAULT_PASSWORD: admin123
    ports:
      - "5050:80"

  spark-master:
    build: 
      context: .
      dockerfile: Dockerfile.spark
    image: spark
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master --port 7077 --webui-port 8081
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
    ports:
      - "8081:8081"
      - "7077:7077"
    volumes:
      - ./scripts:/opt/spark-apps
      - ./spark-artifacts:/tmp/spark-artifacts 

  spark-worker-1:
    build: 
      context: .
      dockerfile: Dockerfile.spark
    image: spark
    container_name: spark-worker-1
    ports:
      - "8082:8082"
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077 --webui-port 8082
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_HOST=spark-master
      - SPARK_WORKER_MEMORY=3G
      - SPARK_WORKER_CORES=2
    volumes:
      - ./scripts:/opt/spark-apps
      - ./spark-artifacts:/tmp/spark-artifacts 
  spark-worker-2:
    build: 
      context: .
      dockerfile: Dockerfile.spark
    image: spark
    container_name: spark-worker-2
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_WORKER_MEMORY=3G
      - SPARK_WORKER_CORES=2
      - SPARK_MODE=worker
      - SPARK_MASTER_HOST=spark-master
    volumes:
      - ./scripts:/opt/spark-apps
      - ./spark-artifacts:/tmp/spark-artifacts 

  airflow:
    image: apache/airflow:2.9.1
    container_name: airflow
    restart: always
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://befood:befood123@postgres:5432/befood_db
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__WEBSERVER__SECRET_KEY: 'your_secret_key_here'
    volumes:
      - ./dags:/opt/airflow/dags
      - ./tmp:/opt/airflow/tmp
      - ./scripts:/opt/airflow/spark_jobs
      - ./requirements.txt:/requirements.txt
      - ./crawl_data:/opt/airflow/crawl_data
    ports:
      - "8088:8080"
    command: >
      bash -c "
        pip install -r /requirements.txt &&
        airflow db migrate &&
        airflow users create --username airflow --firstname Air --lastname Flow --role Admin --email airflow@example.com --password airflow &&
        airflow webserver
      "

volumes:
  mongo_data:
  postgres_data:
